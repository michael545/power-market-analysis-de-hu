{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pd --v: 2.3.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "\n",
    "print(f\"Pd --v: {pd.__version__}\")\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File paths:\n",
      "EPEX (DE) data: c:\\Users\\micha\\code\\power-market-analysis-de-hu\\data\\raw\\Day-ahead_prices_202507070000_202508040000_Hour_Quarterhour.csv\n",
      "HUPX (HU) data: c:\\Users\\micha\\code\\power-market-analysis-de-hu\\data\\raw\\Labs_DAM_Aggregated_Trading_Data_20250802_190631.csv\n",
      "Processed data output: c:\\Users\\micha\\code\\power-market-analysis-de-hu\\data\\processed\n",
      "\n",
      "File existence check:\n",
      "EPEX file exists: True\n",
      "HUPX file exists: True\n"
     ]
    }
   ],
   "source": [
    "project_root = Path.cwd().parent\n",
    "data_raw_path = project_root / \"data\" / \"raw\"\n",
    "data_processed_path = project_root / \"data\" / \"processed\"\n",
    "\n",
    "data_processed_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "epex_file = data_raw_path / \"Day-ahead_prices_202507070000_202508040000_Hour_Quarterhour.csv\"\n",
    "hupx_file = data_raw_path / \"Labs_DAM_Aggregated_Trading_Data_20250802_190631.csv\"\n",
    "\n",
    "print(\"File paths:\")\n",
    "print(f\"EPEX (DE) data: {epex_file}\")\n",
    "print(f\"HUPX (HU) data: {hupx_file}\")\n",
    "print(f\"Processed data output: {data_processed_path}\")\n",
    "\n",
    "print(f\"\\nFile existence check:\")\n",
    "print(f\"EPEX file exists: {epex_file.exists()}\")\n",
    "print(f\"HUPX file exists: {hupx_file.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EPEX data shape: (2688, 19)\n",
      "Columns (19):\n",
      "   1. Start date\n",
      "   2. End date\n",
      "   3. Germany/Luxembourg [€/MWh] Original resolutions\n",
      "   4. ∅ DE/LU neighbours [€/MWh] Original resolutions\n",
      "   5. Belgium [€/MWh] Original resolutions\n",
      "   6. Denmark 1 [€/MWh] Original resolutions\n",
      "   7. Denmark 2 [€/MWh] Original resolutions\n",
      "   8. France [€/MWh] Original resolutions\n",
      "   9. Netherlands [€/MWh] Original resolutions\n",
      "  10. Norway 2 [€/MWh] Original resolutions\n",
      "  11. Austria [€/MWh] Original resolutions\n",
      "  12. Poland [€/MWh] Original resolutions\n",
      "  13. Sweden 4 [€/MWh] Original resolutions\n",
      "  14. Switzerland [€/MWh] Original resolutions\n",
      "  15. Czech Republic [€/MWh] Original resolutions\n",
      "  16. DE/AT/LU [€/MWh] Original resolutions\n",
      "  17. Northern Italy [€/MWh] Original resolutions\n",
      "  18. Slovenia [€/MWh] Original resolutions\n",
      "  19. Hungary [€/MWh] Original resolutions\n",
      "\n",
      "First few rows:\n",
      "             Start date              End date  \\\n",
      "0  Jul 7, 2025 12:00 AM  Jul 7, 2025 12:15 AM   \n",
      "1  Jul 7, 2025 12:15 AM  Jul 7, 2025 12:30 AM   \n",
      "2  Jul 7, 2025 12:30 AM  Jul 7, 2025 12:45 AM   \n",
      "\n",
      "  Germany/Luxembourg [€/MWh] Original resolutions  \\\n",
      "0                                          118.84   \n",
      "1                                               -   \n",
      "2                                               -   \n",
      "\n",
      "  ∅ DE/LU neighbours [€/MWh] Original resolutions  \\\n",
      "0                                          101.34   \n",
      "1                                               -   \n",
      "2                                               -   \n",
      "\n",
      "  Belgium [€/MWh] Original resolutions Denmark 1 [€/MWh] Original resolutions  \\\n",
      "0                               121.49                                 118.84   \n",
      "1                                    -                                      -   \n",
      "2                                    -                                      -   \n",
      "\n",
      "  Denmark 2 [€/MWh] Original resolutions France [€/MWh] Original resolutions  \\\n",
      "0                                 118.84                               46.35   \n",
      "1                                      -                                   -   \n",
      "2                                      -                                   -   \n",
      "\n",
      "  Netherlands [€/MWh] Original resolutions  \\\n",
      "0                                   125.88   \n",
      "1                                        -   \n",
      "2                                        -   \n",
      "\n",
      "  Norway 2 [€/MWh] Original resolutions Austria [€/MWh] Original resolutions  \\\n",
      "0                                 69.82                               116.00   \n",
      "1                                     -                                    -   \n",
      "2                                     -                                    -   \n",
      "\n",
      "  Poland [€/MWh] Original resolutions Sweden 4 [€/MWh] Original resolutions  \\\n",
      "0                              119.21                                 58.23   \n",
      "1                                   -                                     -   \n",
      "2                                   -                                     -   \n",
      "\n",
      "  Switzerland [€/MWh] Original resolutions  \\\n",
      "0                                   101.45   \n",
      "1                                        -   \n",
      "2                                        -   \n",
      "\n",
      "  Czech Republic [€/MWh] Original resolutions  \\\n",
      "0                                      118.61   \n",
      "1                                           -   \n",
      "2                                           -   \n",
      "\n",
      "  DE/AT/LU [€/MWh] Original resolutions  \\\n",
      "0                                     -   \n",
      "1                                     -   \n",
      "2                                     -   \n",
      "\n",
      "   Northern Italy [€/MWh] Original resolutions  \\\n",
      "0                                        116.0   \n",
      "1                                        116.0   \n",
      "2                                        116.0   \n",
      "\n",
      "  Slovenia [€/MWh] Original resolutions Hungary [€/MWh] Original resolutions  \n",
      "0                                115.95                               117.99  \n",
      "1                                     -                                    -  \n",
      "2                                     -                                    -  \n",
      "\n",
      "Data types:\n",
      "Start date                                          object\n",
      "End date                                            object\n",
      "Germany/Luxembourg [€/MWh] Original resolutions     object\n",
      "∅ DE/LU neighbours [€/MWh] Original resolutions     object\n",
      "Belgium [€/MWh] Original resolutions                object\n",
      "Denmark 1 [€/MWh] Original resolutions              object\n",
      "Denmark 2 [€/MWh] Original resolutions              object\n",
      "France [€/MWh] Original resolutions                 object\n",
      "Netherlands [€/MWh] Original resolutions            object\n",
      "Norway 2 [€/MWh] Original resolutions               object\n",
      "Austria [€/MWh] Original resolutions                object\n",
      "Poland [€/MWh] Original resolutions                 object\n",
      "Sweden 4 [€/MWh] Original resolutions               object\n",
      "Switzerland [€/MWh] Original resolutions            object\n",
      "Czech Republic [€/MWh] Original resolutions         object\n",
      "DE/AT/LU [€/MWh] Original resolutions               object\n",
      "Northern Italy [€/MWh] Original resolutions        float64\n",
      "Slovenia [€/MWh] Original resolutions               object\n",
      "Hungary [€/MWh] Original resolutions                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "\n",
    "epex_raw = pd.read_csv(epex_file, sep=';')\n",
    "\n",
    "print(f\"EPEX data shape: {epex_raw.shape}\")\n",
    "print(f\"Columns ({len(epex_raw.columns)}):\")\n",
    "for i, col in enumerate(epex_raw.columns):\n",
    "    print(f\"  {i+1:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(epex_raw.head(3))\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(epex_raw.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HU dataa shape: (504, 6)\n",
      "Cols (6):\n",
      "  1. Delivery day\n",
      "  2. Hour\n",
      "  3. Price\n",
      "  4. Traded volume\n",
      "  5. Baseload price\n",
      "  6. Status\n",
      "\n",
      "First few rows:\n",
      "           Delivery day  Hour   Price  Traded volume  Baseload price Status\n",
      "0  2025-07-27T00:00:00Z    24  121.78         2925.7           92.04  final\n",
      "1  2025-07-27T00:00:00Z    23  163.93         3235.0           92.04  final\n",
      "2  2025-07-27T00:00:00Z    22  180.00         3562.3           92.04  final\n",
      "\n",
      "Data types:\n",
      "Delivery day       object\n",
      "Hour                int64\n",
      "Price             float64\n",
      "Traded volume     float64\n",
      "Baseload price    float64\n",
      "Status             object\n",
      "dtype: object\n",
      "\n",
      "Unique values in 'Status' column:\n",
      "Status\n",
      "final    504\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "hupx_raw = pd.read_csv(hupx_file)\n",
    "\n",
    "print(f\"HU dataa shape: {hupx_raw.shape}\")\n",
    "print(f\"Cols ({len(hupx_raw.columns)}):\")\n",
    "for i, col in enumerate(hupx_raw.columns):\n",
    "    print(f\"  {i+1}. {col}\")\n",
    "\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(hupx_raw.head(3))\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(hupx_raw.dtypes)\n",
    "\n",
    "print(f\"\\nUnique values in 'Status' column:\")\n",
    "print(hupx_raw['Status'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLEANING EPEX DATA\n",
      "============================================================\n",
      "EPEX cleaned data shape: (672, 3)\n",
      "Date range: 2025-07-07 00:00:00 to 2025-08-03 23:00:00\n",
      "Missing values:\n",
      "timestamp_start    0\n",
      "de_price_epex      0\n",
      "hu_price_epex      0\n",
      "dtype: int64\n",
      "\n",
      "First few rows:\n",
      "       timestamp_start  de_price_epex  hu_price_epex\n",
      "0  2025-07-07 00:00:00         118.84         117.99\n",
      "4  2025-07-07 01:00:00         107.42         105.64\n",
      "8  2025-07-07 02:00:00         101.92         100.98\n",
      "12 2025-07-07 03:00:00          99.12          97.67\n",
      "16 2025-07-07 04:00:00         101.00          99.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\AppData\\Local\\Temp\\ipykernel_25940\\986222086.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  epex_clean['timestamp_start'] = pd.to_datetime(epex_clean['timestamp_start'])\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CLEANING EPEX DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "epex_clean = epex_raw[['Start date', 'Germany/Luxembourg [€/MWh] Original resolutions', \n",
    "                       'Hungary [€/MWh] Original resolutions']].copy()\n",
    "\n",
    "epex_clean.columns = ['timestamp_start', 'de_price_epex', 'hu_price_epex']\n",
    "\n",
    "epex_clean['timestamp_start'] = pd.to_datetime(epex_clean['timestamp_start'])\n",
    "\n",
    "epex_clean['de_price_epex'] = pd.to_numeric(epex_clean['de_price_epex'], errors='coerce')\n",
    "epex_clean['hu_price_epex'] = pd.to_numeric(epex_clean['hu_price_epex'], errors='coerce')\n",
    "\n",
    "epex_clean = epex_clean.dropna(subset=['de_price_epex', 'hu_price_epex'], how='all')\n",
    "\n",
    "print(f\"EPEX cleaned data shape: {epex_clean.shape}\")\n",
    "print(f\"Date range: {epex_clean['timestamp_start'].min()} to {epex_clean['timestamp_start'].max()}\")\n",
    "print(f\"Missing values:\")\n",
    "print(epex_clean.isnull().sum())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(epex_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGE EPEX DATA TO HOURLY RESOLUTION\n",
      "EPEX hourly data shape: (672, 3)\n",
      "Date range: 2025-07-07 00:00:00 to 2025-08-03 23:00:00\n",
      "Missing values:\n",
      "timestamp        0\n",
      "de_price_epex    0\n",
      "hu_price_epex    0\n",
      "dtype: int64\n",
      "\n",
      "First few rows:\n",
      "            timestamp  de_price_epex  hu_price_epex\n",
      "0 2025-07-07 00:00:00         118.84         117.99\n",
      "1 2025-07-07 01:00:00         107.42         105.64\n",
      "2 2025-07-07 02:00:00         101.92         100.98\n",
      "3 2025-07-07 03:00:00          99.12          97.67\n",
      "4 2025-07-07 04:00:00         101.00          99.34\n",
      "\n",
      "Time gaps check:\n",
      "Standard interval: 0 days 01:00:00\n",
      "Any non-standard intervals: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\AppData\\Local\\Temp\\ipykernel_25940\\3625668979.py:3: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  epex_clean['hour'] = epex_clean['timestamp_start'].dt.floor('H')\n",
      "C:\\Users\\micha\\AppData\\Local\\Temp\\ipykernel_25940\\3625668979.py:24: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
      "  print(f\"Any non-standard intervals: {(time_diff != pd.Timedelta('1H')).any()}\")\n"
     ]
    }
   ],
   "source": [
    "print(\"CHANGE EPEX DATA TO HOURLY RESOLUTION\")\n",
    "\n",
    "epex_clean['hour'] = epex_clean['timestamp_start'].dt.floor('H')\n",
    "\n",
    "epex_hourly = epex_clean.groupby('hour').agg({\n",
    "    'de_price_epex': 'mean',\n",
    "    'hu_price_epex': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "epex_hourly.rename(columns={'hour': 'timestamp'}, inplace=True)\n",
    "\n",
    "print(f\"EPEX hourly data shape: {epex_hourly.shape}\")\n",
    "print(f\"Date range: {epex_hourly['timestamp'].min()} to {epex_hourly['timestamp'].max()}\")\n",
    "print(f\"Missing values:\")\n",
    "print(epex_hourly.isnull().sum())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(epex_hourly.head())\n",
    "\n",
    "time_diff = epex_hourly['timestamp'].diff().dropna()\n",
    "print(f\"\\nTime gaps check:\")\n",
    "print(f\"Standard interval: {time_diff.mode().iloc[0]}\")\n",
    "print(f\"Any non-standard intervals: {(time_diff != pd.Timedelta('1H')).any()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLEANING HUPX DATA\n",
      "============================================================\n",
      "HUPX cleaned data shape: (504, 2)\n",
      "Date range: 2025-07-07 00:00:00+00:00 to 2025-07-27 23:00:00+00:00\n",
      "Missing values:\n",
      "timestamp        0\n",
      "hu_price_hupx    0\n",
      "dtype: int64\n",
      "\n",
      "First few rows:\n",
      "                  timestamp  hu_price_hupx\n",
      "0 2025-07-07 00:00:00+00:00         117.99\n",
      "1 2025-07-07 01:00:00+00:00         105.64\n",
      "2 2025-07-07 02:00:00+00:00         100.98\n",
      "3 2025-07-07 03:00:00+00:00          97.67\n",
      "4 2025-07-07 04:00:00+00:00          99.34\n",
      "\n",
      "Time gaps check:\n",
      "Standard interval: 0 days 01:00:00\n",
      "Any non-standard intervals: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\AppData\\Local\\Temp\\ipykernel_25940\\124417794.py:40: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
      "  print(f\"Any non-standard intervals: {(time_diff != pd.Timedelta('1H')).any()}\")\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CLEANING HUPX DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "hupx_clean = hupx_raw.copy()\n",
    "\n",
    "columns_to_drop = ['Status', 'Baseload price', 'Traded volume']\n",
    "hupx_clean = hupx_clean.drop(columns=columns_to_drop)\n",
    "\n",
    "hupx_clean.columns = ['delivery_day', 'hour', 'hu_price_hupx']\n",
    "\n",
    "\n",
    "hupx_clean['delivery_day'] = pd.to_datetime(hupx_clean['delivery_day'])\n",
    "\n",
    "\n",
    "hupx_clean['hour_0based'] = hupx_clean['hour'] - 1\n",
    "hupx_clean['timestamp'] = hupx_clean['delivery_day'] + pd.to_timedelta(hupx_clean['hour_0based'], unit='h')\n",
    "\n",
    "\n",
    "hupx_clean = hupx_clean[['timestamp', 'hu_price_hupx']].copy()\n",
    "\n",
    "\n",
    "hupx_clean = hupx_clean.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"HUPX cleaned data shape: {hupx_clean.shape}\")\n",
    "print(f\"Date range: {hupx_clean['timestamp'].min()} to {hupx_clean['timestamp'].max()}\")\n",
    "print(f\"Missing values:\")\n",
    "print(hupx_clean.isnull().sum())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(hupx_clean.head())\n",
    "\n",
    "\n",
    "time_diff = hupx_clean['timestamp'].diff().dropna()\n",
    "print(f\"\\nTime gaps check:\")\n",
    "print(f\"Standard interval: {time_diff.mode().iloc[0]}\")\n",
    "print(f\"Any non-standard intervals: {(time_diff != pd.Timedelta('1H')).any()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MERGING DATASETS\n",
      "============================================================\n",
      "EPEX timestamp info:\n",
      "  Type: datetime64[ns]\n",
      "  Timezone: None\n",
      "  Sample: 2025-07-07 00:00:00\n",
      "\n",
      "HUPX timestamp info:\n",
      "  Type: datetime64[ns, UTC]\n",
      "  Timezone: UTC\n",
      "  Sample: 2025-07-07 00:00:00+00:00\n",
      "\n",
      "Standardizing timestamps to timezone-naive...\n",
      "After standardization:\n",
      "EPEX timestamp type: datetime64[ns]\n",
      "HUPX timestamp type: datetime64[ns]\n",
      "Merged data shape: (672, 4)\n",
      "Date range: 2025-07-07 00:00:00 to 2025-08-03 23:00:00\n",
      "Missing values:\n",
      "timestamp          0\n",
      "de_price_epex      0\n",
      "hu_price_epex      0\n",
      "hu_price_hupx    168\n",
      "dtype: int64\n",
      "\n",
      "Data coverage analysis:\n",
      "EPEX DE prices available: 672 hours\n",
      "EPEX HU prices available: 672 hours\n",
      "HUPX HU prices available: 504 hours\n",
      "Total time periods: 672 hours\n",
      "\n",
      "First few rows:\n",
      "            timestamp  de_price_epex  hu_price_epex  hu_price_hupx\n",
      "0 2025-07-07 00:00:00         118.84         117.99         117.99\n",
      "1 2025-07-07 01:00:00         107.42         105.64         105.64\n",
      "2 2025-07-07 02:00:00         101.92         100.98         100.98\n",
      "3 2025-07-07 03:00:00          99.12          97.67          97.67\n",
      "4 2025-07-07 04:00:00         101.00          99.34          99.34\n",
      "5 2025-07-07 05:00:00         108.22         109.29         109.29\n",
      "6 2025-07-07 06:00:00         134.20         131.70         131.70\n",
      "7 2025-07-07 07:00:00         143.67         139.17         139.17\n",
      "8 2025-07-07 08:00:00         152.29         145.28         145.28\n",
      "9 2025-07-07 09:00:00         131.99         130.87         130.87\n",
      "\n",
      "Last few rows:\n",
      "              timestamp  de_price_epex  hu_price_epex  hu_price_hupx\n",
      "662 2025-08-03 14:00:00         -10.08         -10.08            NaN\n",
      "663 2025-08-03 15:00:00          -4.98          -4.98            NaN\n",
      "664 2025-08-03 16:00:00          -1.50           0.28            NaN\n",
      "665 2025-08-03 17:00:00           3.61          86.81            NaN\n",
      "666 2025-08-03 18:00:00          71.13         116.62            NaN\n",
      "667 2025-08-03 19:00:00          88.13         111.00            NaN\n",
      "668 2025-08-03 20:00:00          97.87         149.65            NaN\n",
      "669 2025-08-03 21:00:00          95.99         125.82            NaN\n",
      "670 2025-08-03 22:00:00          97.30         112.56            NaN\n",
      "671 2025-08-03 23:00:00          85.09          85.09            NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nStandardizing timestamps to timezone-naive...\")\n",
    "\n",
    "epex_hourly['timestamp'] = pd.to_datetime(epex_hourly['timestamp']).dt.tz_localize(None)\n",
    "hupx_clean['timestamp'] = pd.to_datetime(hupx_clean['timestamp']).dt.tz_localize(None)\n",
    "\n",
    "print(\"After standardization:\")\n",
    "print(f\"EPEX timestamp type: {epex_hourly['timestamp'].dtype}\")\n",
    "print(f\"HUPX timestamp type: {hupx_clean['timestamp'].dtype}\")\n",
    "\n",
    "merged_data = pd.merge(epex_hourly, hupx_clean, on='timestamp', how='outer')\n",
    "\n",
    "merged_data = merged_data.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"Merged data shape: {merged_data.shape}\")\n",
    "print(f\"Date range: {merged_data['timestamp'].min()} to {merged_data['timestamp'].max()}\")\n",
    "print(f\"Missing values:\")\n",
    "print(merged_data.isnull().sum())\n",
    "\n",
    "print(f\"\\nData coverage analysis:\")\n",
    "print(f\"EPEX DE prices available: {merged_data['de_price_epex'].notna().sum()} hours\")\n",
    "print(f\"EPEX HU prices available: {merged_data['hu_price_epex'].notna().sum()} hours\")\n",
    "print(f\"HUPX HU prices available: {merged_data['hu_price_hupx'].notna().sum()} hours\")\n",
    "print(f\"Total time periods: {len(merged_data)} hours\")\n",
    "\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(merged_data.head(10))\n",
    "\n",
    "print(f\"\\nLast few rows:\")\n",
    "print(merged_data.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ADDING DERIVED COLUMNS FOR ANALYSIS\n",
      "============================================================\n",
      "Enhanced data shape: (672, 15)\n",
      "Columns: ['timestamp', 'de_price_epex', 'hu_price_epex', 'hu_price_hupx', 'date', 'hour', 'weekday', 'week_number', 'month', 'hu_price_primary', 'de_hu_spread', 'epex_hupx_hu_spread', 'has_de_price', 'has_hu_hupx', 'has_hu_epex']\n",
      "\n",
      "Weeks covered: [np.uint32(28), np.uint32(29), np.uint32(30), np.uint32(31)]\n",
      "\n",
      "Target weeks (28, 29, 30) data shape: (504, 15)\n",
      "Date range for target weeks: 2025-07-07 00:00:00 to 2025-07-27 23:00:00\n",
      "\n",
      "Data availability by week:\n",
      "Week 28: 168 hours, DE prices: 168, HU HUPX: 168\n",
      "Week 29: 168 hours, DE prices: 168, HU HUPX: 168\n",
      "Week 30: 168 hours, DE prices: 168, HU HUPX: 168\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ADDING DERIVED COLUMNS FOR ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "merged_data['date'] = merged_data['timestamp'].dt.date\n",
    "merged_data['hour'] = merged_data['timestamp'].dt.hour\n",
    "merged_data['weekday'] = merged_data['timestamp'].dt.day_name()\n",
    "merged_data['week_number'] = merged_data['timestamp'].dt.isocalendar().week\n",
    "merged_data['month'] = merged_data['timestamp'].dt.month\n",
    "\n",
    "merged_data['hu_price_primary'] = merged_data['hu_price_hupx'].fillna(merged_data['hu_price_epex'])\n",
    "\n",
    "merged_data['de_hu_spread'] = merged_data['de_price_epex'] - merged_data['hu_price_primary']\n",
    "merged_data['epex_hupx_hu_spread'] = merged_data['hu_price_epex'] - merged_data['hu_price_hupx']\n",
    "\n",
    "merged_data['has_de_price'] = merged_data['de_price_epex'].notna()\n",
    "merged_data['has_hu_hupx'] = merged_data['hu_price_hupx'].notna()\n",
    "merged_data['has_hu_epex'] = merged_data['hu_price_epex'].notna()\n",
    "\n",
    "print(f\"Enhanced data shape: {merged_data.shape}\")\n",
    "print(f\"Columns: {list(merged_data.columns)}\")\n",
    "\n",
    "weeks_covered = sorted(merged_data['week_number'].dropna().unique())\n",
    "print(f\"\\nWeeks covered: {weeks_covered}\")\n",
    "\n",
    "target_weeks = [28, 29, 30]\n",
    "target_data = merged_data[merged_data['week_number'].isin(target_weeks)].copy()\n",
    "\n",
    "print(f\"\\nTarget weeks (28, 29, 30) data shape: {target_data.shape}\")\n",
    "print(f\"Date range for target weeks: {target_data['timestamp'].min()} to {target_data['timestamp'].max()}\")\n",
    "\n",
    "print(f\"\\nData availability by week:\")\n",
    "for week in target_weeks:\n",
    "    week_data = target_data[target_data['week_number'] == week]\n",
    "    print(f\"Week {week}: {len(week_data)} hours, DE prices: {week_data['has_de_price'].sum()}, HU HUPX: {week_data['has_hu_hupx'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA QUALITY REPORT\n",
      "============================================================\n",
      "SUMMARY STATISTICS FOR WEEKS 28, 29, 30:\n",
      "==================================================\n",
      "       de_price_epex  hu_price_hupx  hu_price_epex  hu_price_primary  \\\n",
      "count     504.000000     504.000000     504.000000        504.000000   \n",
      "mean       88.260556     103.049325     103.049325        103.049325   \n",
      "std        30.603741      47.015873      47.015873         47.015873   \n",
      "min        -0.010000      -0.010000      -0.010000         -0.010000   \n",
      "25%        79.650000      85.220000      85.220000         85.220000   \n",
      "50%        94.025000     100.965000     100.965000        100.965000   \n",
      "75%       108.167500     116.512500     116.512500        116.512500   \n",
      "max       154.160000     386.030000     386.030000        386.030000   \n",
      "\n",
      "       de_hu_spread  \n",
      "count    504.000000  \n",
      "mean     -14.788770  \n",
      "std       31.987004  \n",
      "min     -276.750000  \n",
      "25%      -20.912500  \n",
      "50%       -2.640000  \n",
      "75%        0.662500  \n",
      "max       29.050000  \n",
      "\n",
      "MISSING DATA ANALYSIS:\n",
      "==============================\n",
      "Total hours in target weeks: 504\n",
      "de_price_epex: 0 missing (0.0%)\n",
      "hu_price_hupx: 0 missing (0.0%)\n",
      "hu_price_epex: 0 missing (0.0%)\n",
      "\n",
      "DATA AVAILABILITY BY WEEK:\n",
      "==============================\n",
      "\n",
      "Week 28 (168 hours):\n",
      "  DE prices: 168/168 (100.0%)\n",
      "  HU HUPX:   168/168 (100.0%)\n",
      "\n",
      "Week 29 (168 hours):\n",
      "  DE prices: 168/168 (100.0%)\n",
      "  HU HUPX:   168/168 (100.0%)\n",
      "\n",
      "Week 30 (168 hours):\n",
      "  DE prices: 168/168 (100.0%)\n",
      "  HU HUPX:   168/168 (100.0%)\n",
      "\n",
      "PRICE ANOMALY CHECK:\n",
      "=========================\n",
      "Negative DE prices: 2\n",
      "Negative HU prices: 2\n",
      "Very high DE prices (>500): 0\n",
      "Very high HU prices (>500): 0\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DATA QUALITY REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"SUMMARY STATISTICS FOR WEEKS 28, 29, 30:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summary_stats = target_data[['de_price_epex', 'hu_price_hupx', 'hu_price_epex', \n",
    "                             'hu_price_primary', 'de_hu_spread']].describe()\n",
    "print(summary_stats)\n",
    "\n",
    "print(f\"\\nMISSING DATA ANALYSIS:\")\n",
    "print(\"=\" * 30)\n",
    "missing_analysis = target_data[['de_price_epex', 'hu_price_hupx', 'hu_price_epex']].isnull().sum()\n",
    "total_hours = len(target_data)\n",
    "print(f\"Total hours in target weeks: {total_hours}\")\n",
    "for col, missing_count in missing_analysis.items():\n",
    "    pct_missing = (missing_count / total_hours) * 100\n",
    "    print(f\"{col}: {missing_count} missing ({pct_missing:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDATA AVAILABILITY BY WEEK:\")\n",
    "print(\"=\" * 30)\n",
    "for week in target_weeks:\n",
    "    week_data = target_data[target_data['week_number'] == week]\n",
    "    total_week_hours = len(week_data)\n",
    "    de_available = week_data['de_price_epex'].notna().sum()\n",
    "    hu_hupx_available = week_data['hu_price_hupx'].notna().sum()\n",
    "    \n",
    "    print(f\"\\nWeek {week} ({total_week_hours} hours):\")\n",
    "    print(f\"  DE prices: {de_available}/{total_week_hours} ({de_available/total_week_hours*100:.1f}%)\")\n",
    "    print(f\"  HU HUPX:   {hu_hupx_available}/{total_week_hours} ({hu_hupx_available/total_week_hours*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nPRICE ANOMALY CHECK:\")\n",
    "print(\"=\" * 25)\n",
    "neg_de = (target_data['de_price_epex'] < 0).sum()\n",
    "neg_hu = (target_data['hu_price_primary'] < 0).sum()\n",
    "print(f\"Negative DE prices: {neg_de}\")\n",
    "print(f\"Negative HU prices: {neg_hu}\")\n",
    "\n",
    "high_de = (target_data['de_price_epex'] > 500).sum()\n",
    "high_hu = (target_data['hu_price_primary'] > 500).sum()\n",
    "print(f\"Very high DE prices (>500): {high_de}\")\n",
    "print(f\"Very high HU prices (>500): {high_hu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPORTING CLEANED DATA\n",
      "============================================================\n",
      "Full dataset exported to: c:\\Users\\micha\\code\\power-market-analysis-de-hu\\data\\processed\\merged_spot_prices_full.csv\n",
      "Target weeks dataset exported to: c:\\Users\\micha\\code\\power-market-analysis-de-hu\\data\\processed\\spot_prices_weeks_28_29_30.csv\n",
      "Daily summary exported to: c:\\Users\\micha\\code\\power-market-analysis-de-hu\\data\\processed\\daily_summary_weeks_28_29_30.csv\n",
      "\n",
      "Data processing completed successfully!\n",
      "Files created:\n",
      "  1. merged_spot_prices_full.csv - Full merged dataset (672 hours)\n",
      "  2. spot_prices_weeks_28_29_30.csv - Target weeks only (504 hours)\n",
      "  3. daily_summary_weeks_28_29_30.csv - Daily summaries (21 days)\n",
      "\n",
      "FINAL PREVIEW - WEEKS 28, 29, 30:\n",
      "========================================\n",
      "            timestamp  week_number  de_price_epex  hu_price_hupx  \\\n",
      "0 2025-07-07 00:00:00           28         118.84         117.99   \n",
      "1 2025-07-07 01:00:00           28         107.42         105.64   \n",
      "2 2025-07-07 02:00:00           28         101.92         100.98   \n",
      "3 2025-07-07 03:00:00           28          99.12          97.67   \n",
      "4 2025-07-07 04:00:00           28         101.00          99.34   \n",
      "5 2025-07-07 05:00:00           28         108.22         109.29   \n",
      "6 2025-07-07 06:00:00           28         134.20         131.70   \n",
      "7 2025-07-07 07:00:00           28         143.67         139.17   \n",
      "8 2025-07-07 08:00:00           28         152.29         145.28   \n",
      "9 2025-07-07 09:00:00           28         131.99         130.87   \n",
      "\n",
      "   hu_price_primary  de_hu_spread  \n",
      "0            117.99          0.85  \n",
      "1            105.64          1.78  \n",
      "2            100.98          0.94  \n",
      "3             97.67          1.45  \n",
      "4             99.34          1.66  \n",
      "5            109.29         -1.07  \n",
      "6            131.70          2.50  \n",
      "7            139.17          4.50  \n",
      "8            145.28          7.01  \n",
      "9            130.87          1.12  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "full_output_file = data_processed_path / \"merged_spot_prices_full.csv\"\n",
    "merged_data.to_csv(full_output_file, index=False)\n",
    "print(f\"Full dataset exported to: {full_output_file}\")\n",
    "\n",
    "target_output_file = data_processed_path / \"spot_prices_weeks_28_29_30.csv\"\n",
    "target_data.to_csv(target_output_file, index=False)\n",
    "print(f\"Target weeks dataset exported to: {target_output_file}\")\n",
    "\n",
    "summary_data = target_data.groupby(['week_number', 'date']).agg({\n",
    "    'de_price_epex': ['mean', 'min', 'max'],\n",
    "    'hu_price_primary': ['mean', 'min', 'max'],\n",
    "    'de_hu_spread': ['mean', 'min', 'max'],\n",
    "    'has_de_price': 'sum',\n",
    "    'has_hu_hupx': 'sum'\n",
    "}).round(2)\n",
    "\n",
    "summary_data.columns = ['_'.join(col).strip() for col in summary_data.columns]\n",
    "summary_data = summary_data.reset_index()\n",
    "\n",
    "summary_output_file = data_processed_path / \"daily_summary_weeks_28_29_30.csv\"\n",
    "summary_data.to_csv(summary_output_file, index=False)\n",
    "print(f\"Daily summary exported to: {summary_output_file}\")\n",
    "\n",
    "print(f\"Files created:\")\n",
    "print(f\"  1. {full_output_file.name} - Full merged dataset ({len(merged_data)} hours)\")\n",
    "print(f\"  2. {target_output_file.name} - Target weeks only ({len(target_data)} hours)\")\n",
    "print(f\"  3. {summary_output_file.name} - Daily summaries ({len(summary_data)} days)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "power-market-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
